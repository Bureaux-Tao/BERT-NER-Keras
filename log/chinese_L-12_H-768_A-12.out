结合"1、左肺上叶尖后段结节影较前稍大、密实，建议随访或进一步检查除外占位；余左肺多发结节影部分较前缩小，请随访；2.左肺上叶上舌段支气管扩张合并感染可能较前相仿；3、右肺结节影及斑片影较前相仿，炎症可能，真菌性感染待排；4、纵隔内多发淋巴结较前相仿。 ['O', 'O', 'O', 'O', 'O', 'B-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'B-QUANTITY', 'I-QUANTITY', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'B-QUANTITY', 'I-QUANTITY', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'B-ORGAN', 'I-ORGAN', 'I-ORGAN', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ANATOMY', 'I-ANATOMY', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'O', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'O', 'B-SIGN', 'I-SIGN', 'B-QUANTITY', 'I-QUANTITY', 'O', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'O', 'O', 'O', 'O', 'O', 'B-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'B-QUANTITY', 'I-QUANTITY', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'O', 'O', 'O', 'O', 'O']
对比2019-05-23：两肺纹理增深，左肺上叶尖后段结节影较前稍大、密实，周围表现大致相仿；余左肺多发大小不等结节影部分较前缩小；左肺下叶背段结节空洞较前不明显；左肺上叶上舌段纵隔旁局部多发囊状透亮影较前相仿，右肺上叶前段及下叶背段见结节影及斑片状模糊影较前大致相仿。 ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ANATOMY', 'I-ANATOMY', 'O', 'O', 'B-TEXTURE', 'I-TEXTURE', 'O', 'B-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'B-QUANTITY', 'I-QUANTITY', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'B-QUANTITY', 'I-QUANTITY', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'O', 'B-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'B-DISEASE', 'I-DISEASE', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'O', 'B-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'O', 'O', 'B-QUANTITY', 'I-QUANTITY', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'O', 'O', 'O', 'O', 'O', 'B-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'O', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'O', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'O', 'O', 'O', 'O', 'O', 'O', 'O']
纵隔心影基本居中，心影大小可。 ['B-ANATOMY', 'I-ANATOMY', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'O', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'O']
主动脉弓旁及上腔静脉后淋巴结多发淋巴结较前相仿。 ['B-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'B-ORGAN', 'I-ORGAN', 'I-ORGAN', 'B-QUANTITY', 'I-QUANTITY', 'B-ORGAN', 'I-ORGAN', 'I-ORGAN', 'O', 'O', 'O', 'O', 'O']
纵隔肺门血管界面显示欠清。 ['B-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'B-ORGAN', 'I-ORGAN', 'O', 'O', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'O']
"两肺散在微小结节影，主动脉弓右前方囊性灶。 ['O', 'B-ANATOMY', 'I-ANATOMY', 'O', 'O', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'O', 'B-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'O']
附见肝脏脂肪浸润，副脾。 ['O', 'O', 'B-ORGAN', 'I-ORGAN', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'O', 'O', 'O', 'O']
Img62、71、97示右侧水平裂处、右中肺及左下肺结节影两肺门区未见异常密度影。 ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'O', 'B-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'B-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'B-QUANTITY', 'I-QUANTITY', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'O']
胸膜未见增厚改变。 ['B-ANATOMY', 'I-ANATOMY', 'B-QUANTITY', 'I-QUANTITY', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'O']
主动脉，肺动脉主干及其左右分支内造影剂密度均匀。 ['B-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'O', 'O', 'O', 'B-DENSITY', 'I-DENSITY', 'O']
"左下肺局限性肺不张，纵隔左移，结核待排两上肺散在炎症，较前2020-5-19吸收左肺结节，较前相仿左肺下叶肺大泡；左侧胸廓较对侧略塌陷，左下肺不张，两上肺散在斑片影，左肺多发小结节，良性增殖灶可能，左肺下叶肺大泡。 ['O', 'B-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'O', 'B-ANATOMY', 'I-ANATOMY', 'B-SIGN', 'I-SIGN', 'O', 'B-DISEASE', 'I-DISEASE', 'O', 'O', 'B-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'O', 'O', 'B-DISEASE', 'I-DISEASE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ANATOMY', 'I-ANATOMY', 'B-DISEASE', 'I-DISEASE', 'O', 'O', 'O', 'O', 'O', 'B-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'B-DISEASE', 'I-DISEASE', 'I-DISEASE', 'O', 'B-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'O', 'B-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'B-SIGN', 'I-SIGN', 'O', 'B-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'O', 'O', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'O', 'B-ANATOMY', 'I-ANATOMY', 'B-QUANTITY', 'I-QUANTITY', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'O', 'B-NATURE', 'I-NATURE', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'O', 'B-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'O']
气管及双侧支气管通畅。 ['B-ORGAN', 'I-ORGAN', 'O', 'B-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'B-SIGN', 'I-SIGN', 'O']
纵隔、肺门未见明显肿大淋巴结影。 ['B-ANATOMY', 'I-ANATOMY', 'O', 'B-ANATOMY', 'I-ANATOMY', 'B-QUANTITY', 'I-QUANTITY', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'O']
左侧胸腔少量积液。 ['B-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'B-QUANTITY', 'I-QUANTITY', 'B-SIGN', 'I-SIGN', 'O']
两侧胸膜未见明显增厚。 ['B-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'B-QUANTITY', 'I-QUANTITY', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'O']
""左肺术后改变同前，请随访。 ['O', 'O', 'B-TREATMENT', 'I-TREATMENT', 'I-TREATMENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']
右肺结节治疗后，右肺上叶磨玻璃结节及实性结节，大致同前，建议结合临床随访。 ['B-ANATOMY', 'I-ANATOMY', 'B-DISEASE', 'I-DISEASE', 'O', 'O', 'O', 'O', 'B-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'B-DISEASE', 'I-DISEASE', 'I-DISEASE', 'I-DISEASE', 'I-DISEASE', 'O', 'B-DISEASE', 'I-DISEASE', 'I-DISEASE', 'I-DISEASE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']
右肺数枚微小结节同前，良性，请随访。 ['B-ANATOMY', 'I-ANATOMY', 'B-QUANTITY', 'I-QUANTITY', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'I-SIGN', 'O', 'O', 'O', 'B-NATURE', 'I-NATURE', 'O', 'O', 'O', 'O', 'O']
右肺上叶炎症同前相仿，良性可能，建议随访。 ['B-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'I-ANATOMY', 'B-DISEASE', 'I-DISEASE', 'O', 'O', 'O', 'O', 'O', 'B-NATURE', 'I-NATURE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']Using TensorFlow backend.
/home/bureaux/miniconda3/envs/Bert-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/bureaux/miniconda3/envs/Bert-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/bureaux/miniconda3/envs/Bert-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/bureaux/miniconda3/envs/Bert-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/bureaux/miniconda3/envs/Bert-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/bureaux/miniconda3/envs/Bert-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/bureaux/miniconda3/envs/Bert-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/bureaux/miniconda3/envs/Bert-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/bureaux/miniconda3/envs/Bert-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/bureaux/miniconda3/envs/Bert-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/bureaux/miniconda3/envs/Bert-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/bureaux/miniconda3/envs/Bert-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Bert-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Bert-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Bert-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Bert-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Bert-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Bert-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Bert-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2974: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where

对比2019-12-3片：左肺术后，左肺见条索影。 ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TREATMENT', 'I-TREATMENT', 'I-TREATMENT', 'O', 'O', 'B-ANATOMY', 'I-ANATOMY', 'O', 'B-SIGN', 'I-SIGN', 'I-SIGN', 'O']
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]

load bert Model start!
load bert Model end!
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
Input-Token (InputLayer)        (None, 150)          0
__________________________________________________________________________________________________
Input-Segment (InputLayer)      (None, 150)          0
__________________________________________________________________________________________________
Embedding-Token (TokenEmbedding [(None, 150, 768), ( 16226304    Input-Token[0][0]
__________________________________________________________________________________________________
Embedding-Segment (Embedding)   (None, 150, 768)     1536        Input-Segment[0][0]
__________________________________________________________________________________________________
Embedding-Token-Segment (Add)   (None, 150, 768)     0           Embedding-Token[0][0]
                                                                 Embedding-Segment[0][0]
__________________________________________________________________________________________________
Embedding-Position (PositionEmb (None, 150, 768)     115200      Embedding-Token-Segment[0][0]
__________________________________________________________________________________________________
Embedding-Dropout (Dropout)     (None, 150, 768)     0           Embedding-Position[0][0]
__________________________________________________________________________________________________
Embedding-Norm (LayerNormalizat (None, 150, 768)     1536        Embedding-Dropout[0][0]
__________________________________________________________________________________________________
Encoder-1-MultiHeadSelfAttentio (None, 150, 768)     2362368     Embedding-Norm[0][0]
__________________________________________________________________________________________________
Encoder-1-MultiHeadSelfAttentio (None, 150, 768)     0           Encoder-1-MultiHeadSelfAttention[
__________________________________________________________________________________________________
Encoder-1-MultiHeadSelfAttentio (None, 150, 768)     0           Embedding-Norm[0][0]
                                                                 Encoder-1-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-1-MultiHeadSelfAttentio (None, 150, 768)     1536        Encoder-1-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-1-FeedForward (FeedForw (None, 150, 768)     4722432     Encoder-1-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-1-FeedForward-Dropout ( (None, 150, 768)     0           Encoder-1-FeedForward[0][0]
__________________________________________________________________________________________________
Encoder-1-FeedForward-Add (Add) (None, 150, 768)     0           Encoder-1-MultiHeadSelfAttention-
                                                                 Encoder-1-FeedForward-Dropout[0][
__________________________________________________________________________________________________
Encoder-1-FeedForward-Norm (Lay (None, 150, 768)     1536        Encoder-1-FeedForward-Add[0][0]
__________________________________________________________________________________________________
Encoder-2-MultiHeadSelfAttentio (None, 150, 768)     2362368     Encoder-1-FeedForward-Norm[0][0]
__________________________________________________________________________________________________
Encoder-2-MultiHeadSelfAttentio (None, 150, 768)     0           Encoder-2-MultiHeadSelfAttention[
__________________________________________________________________________________________________
Encoder-2-MultiHeadSelfAttentio (None, 150, 768)     0           Encoder-1-FeedForward-Norm[0][0]
                                                                 Encoder-2-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-2-MultiHeadSelfAttentio (None, 150, 768)     1536        Encoder-2-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-2-FeedForward (FeedForw (None, 150, 768)     4722432     Encoder-2-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-2-FeedForward-Dropout ( (None, 150, 768)     0           Encoder-2-FeedForward[0][0]
__________________________________________________________________________________________________
Encoder-2-FeedForward-Add (Add) (None, 150, 768)     0           Encoder-2-MultiHeadSelfAttention-
                                                                 Encoder-2-FeedForward-Dropout[0][
__________________________________________________________________________________________________
Encoder-2-FeedForward-Norm (Lay (None, 150, 768)     1536        Encoder-2-FeedForward-Add[0][0]
__________________________________________________________________________________________________
Encoder-3-MultiHeadSelfAttentio (None, 150, 768)     2362368     Encoder-2-FeedForward-Norm[0][0]
__________________________________________________________________________________________________
Encoder-3-MultiHeadSelfAttentio (None, 150, 768)     0           Encoder-3-MultiHeadSelfAttention[
__________________________________________________________________________________________________
Encoder-3-MultiHeadSelfAttentio (None, 150, 768)     0           Encoder-2-FeedForward-Norm[0][0]
                                                                 Encoder-3-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-3-MultiHeadSelfAttentio (None, 150, 768)     1536        Encoder-3-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-3-FeedForward (FeedForw (None, 150, 768)     4722432     Encoder-3-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-3-FeedForward-Dropout ( (None, 150, 768)     0           Encoder-3-FeedForward[0][0]
__________________________________________________________________________________________________
Encoder-3-FeedForward-Add (Add) (None, 150, 768)     0           Encoder-3-MultiHeadSelfAttention-
                                                                 Encoder-3-FeedForward-Dropout[0][
__________________________________________________________________________________________________
Encoder-3-FeedForward-Norm (Lay (None, 150, 768)     1536        Encoder-3-FeedForward-Add[0][0]
__________________________________________________________________________________________________
Encoder-4-MultiHeadSelfAttentio (None, 150, 768)     2362368     Encoder-3-FeedForward-Norm[0][0]
__________________________________________________________________________________________________
Encoder-4-MultiHeadSelfAttentio (None, 150, 768)     0           Encoder-4-MultiHeadSelfAttention[
__________________________________________________________________________________________________
Encoder-4-MultiHeadSelfAttentio (None, 150, 768)     0           Encoder-3-FeedForward-Norm[0][0]
                                                                 Encoder-4-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-4-MultiHeadSelfAttentio (None, 150, 768)     1536        Encoder-4-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-4-FeedForward (FeedForw (None, 150, 768)     4722432     Encoder-4-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-4-FeedForward-Dropout ( (None, 150, 768)     0           Encoder-4-FeedForward[0][0]
__________________________________________________________________________________________________
Encoder-4-FeedForward-Add (Add) (None, 150, 768)     0           Encoder-4-MultiHeadSelfAttention-
                                                                 Encoder-4-FeedForward-Dropout[0][
__________________________________________________________________________________________________
Encoder-4-FeedForward-Norm (Lay (None, 150, 768)     1536        Encoder-4-FeedForward-Add[0][0]
__________________________________________________________________________________________________
Encoder-5-MultiHeadSelfAttentio (None, 150, 768)     2362368     Encoder-4-FeedForward-Norm[0][0]
__________________________________________________________________________________________________
Encoder-5-MultiHeadSelfAttentio (None, 150, 768)     0           Encoder-5-MultiHeadSelfAttention[
__________________________________________________________________________________________________
Encoder-5-MultiHeadSelfAttentio (None, 150, 768)     0           Encoder-4-FeedForward-Norm[0][0]
                                                                 Encoder-5-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-5-MultiHeadSelfAttentio (None, 150, 768)     1536        Encoder-5-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-5-FeedForward (FeedForw (None, 150, 768)     4722432     Encoder-5-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-5-FeedForward-Dropout ( (None, 150, 768)     0           Encoder-5-FeedForward[0][0]
__________________________________________________________________________________________________
Encoder-5-FeedForward-Add (Add) (None, 150, 768)     0           Encoder-5-MultiHeadSelfAttention-
                                                                 Encoder-5-FeedForward-Dropout[0][
__________________________________________________________________________________________________
Encoder-5-FeedForward-Norm (Lay (None, 150, 768)     1536        Encoder-5-FeedForward-Add[0][0]
__________________________________________________________________________________________________
Encoder-6-MultiHeadSelfAttentio (None, 150, 768)     2362368     Encoder-5-FeedForward-Norm[0][0]
__________________________________________________________________________________________________
Encoder-6-MultiHeadSelfAttentio (None, 150, 768)     0           Encoder-6-MultiHeadSelfAttention[
__________________________________________________________________________________________________
Encoder-6-MultiHeadSelfAttentio (None, 150, 768)     0           Encoder-5-FeedForward-Norm[0][0]
                                                                 Encoder-6-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-6-MultiHeadSelfAttentio (None, 150, 768)     1536        Encoder-6-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-6-FeedForward (FeedForw (None, 150, 768)     4722432     Encoder-6-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-6-FeedForward-Dropout ( (None, 150, 768)     0           Encoder-6-FeedForward[0][0]
__________________________________________________________________________________________________
Encoder-6-FeedForward-Add (Add) (None, 150, 768)     0           Encoder-6-MultiHeadSelfAttention-
                                                                 Encoder-6-FeedForward-Dropout[0][
__________________________________________________________________________________________________
Encoder-6-FeedForward-Norm (Lay (None, 150, 768)     1536        Encoder-6-FeedForward-Add[0][0]
__________________________________________________________________________________________________
Encoder-7-MultiHeadSelfAttentio (None, 150, 768)     2362368     Encoder-6-FeedForward-Norm[0][0]
__________________________________________________________________________________________________
Encoder-7-MultiHeadSelfAttentio (None, 150, 768)     0           Encoder-7-MultiHeadSelfAttention[
__________________________________________________________________________________________________
Encoder-7-MultiHeadSelfAttentio (None, 150, 768)     0           Encoder-6-FeedForward-Norm[0][0]
                                                                 Encoder-7-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-7-MultiHeadSelfAttentio (None, 150, 768)     1536        Encoder-7-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-7-FeedForward (FeedForw (None, 150, 768)     4722432     Encoder-7-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-7-FeedForward-Dropout ( (None, 150, 768)     0           Encoder-7-FeedForward[0][0]
__________________________________________________________________________________________________
Encoder-7-FeedForward-Add (Add) (None, 150, 768)     0           Encoder-7-MultiHeadSelfAttention-
                                                                 Encoder-7-FeedForward-Dropout[0][
__________________________________________________________________________________________________
Encoder-7-FeedForward-Norm (Lay (None, 150, 768)     1536        Encoder-7-FeedForward-Add[0][0]
__________________________________________________________________________________________________
Encoder-8-MultiHeadSelfAttentio (None, 150, 768)     2362368     Encoder-7-FeedForward-Norm[0][0]
__________________________________________________________________________________________________
Encoder-8-MultiHeadSelfAttentio (None, 150, 768)     0           Encoder-8-MultiHeadSelfAttention[
__________________________________________________________________________________________________
Encoder-8-MultiHeadSelfAttentio (None, 150, 768)     0           Encoder-7-FeedForward-Norm[0][0]
                                                                 Encoder-8-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-8-MultiHeadSelfAttentio (None, 150, 768)     1536        Encoder-8-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-8-FeedForward (FeedForw (None, 150, 768)     4722432     Encoder-8-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-8-FeedForward-Dropout ( (None, 150, 768)     0           Encoder-8-FeedForward[0][0]
__________________________________________________________________________________________________
Encoder-8-FeedForward-Add (Add) (None, 150, 768)     0           Encoder-8-MultiHeadSelfAttention-
                                                                 Encoder-8-FeedForward-Dropout[0][
__________________________________________________________________________________________________
Encoder-8-FeedForward-Norm (Lay (None, 150, 768)     1536        Encoder-8-FeedForward-Add[0][0]
__________________________________________________________________________________________________
Encoder-9-MultiHeadSelfAttentio (None, 150, 768)     2362368     Encoder-8-FeedForward-Norm[0][0]
__________________________________________________________________________________________________
Encoder-9-MultiHeadSelfAttentio (None, 150, 768)     0           Encoder-9-MultiHeadSelfAttention[
__________________________________________________________________________________________________
Encoder-9-MultiHeadSelfAttentio (None, 150, 768)     0           Encoder-8-FeedForward-Norm[0][0]
                                                                 Encoder-9-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-9-MultiHeadSelfAttentio (None, 150, 768)     1536        Encoder-9-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-9-FeedForward (FeedForw (None, 150, 768)     4722432     Encoder-9-MultiHeadSelfAttention-
__________________________________________________________________________________________________
Encoder-9-FeedForward-Dropout ( (None, 150, 768)     0           Encoder-9-FeedForward[0][0]
__________________________________________________________________________________________________
Encoder-9-FeedForward-Add (Add) (None, 150, 768)     0           Encoder-9-MultiHeadSelfAttention-
                                                                 Encoder-9-FeedForward-Dropout[0][
__________________________________________________________________________________________________
Encoder-9-FeedForward-Norm (Lay (None, 150, 768)     1536        Encoder-9-FeedForward-Add[0][0]
__________________________________________________________________________________________________
Encoder-10-MultiHeadSelfAttenti (None, 150, 768)     2362368     Encoder-9-FeedForward-Norm[0][0]
__________________________________________________________________________________________________
Encoder-10-MultiHeadSelfAttenti (None, 150, 768)     0           Encoder-10-MultiHeadSelfAttention
__________________________________________________________________________________________________
Encoder-10-MultiHeadSelfAttenti (None, 150, 768)     0           Encoder-9-FeedForward-Norm[0][0]
                                                                 Encoder-10-MultiHeadSelfAttention
__________________________________________________________________________________________________
Encoder-10-MultiHeadSelfAttenti (None, 150, 768)     1536        Encoder-10-MultiHeadSelfAttention
__________________________________________________________________________________________________
Encoder-10-FeedForward (FeedFor (None, 150, 768)     4722432     Encoder-10-MultiHeadSelfAttention
__________________________________________________________________________________________________
Encoder-10-FeedForward-Dropout  (None, 150, 768)     0           Encoder-10-FeedForward[0][0]
__________________________________________________________________________________________________
Encoder-10-FeedForward-Add (Add (None, 150, 768)     0           Encoder-10-MultiHeadSelfAttention
                                                                 Encoder-10-FeedForward-Dropout[0]
__________________________________________________________________________________________________
Encoder-10-FeedForward-Norm (La (None, 150, 768)     1536        Encoder-10-FeedForward-Add[0][0]
__________________________________________________________________________________________________
Encoder-11-MultiHeadSelfAttenti (None, 150, 768)     2362368     Encoder-10-FeedForward-Norm[0][0]
__________________________________________________________________________________________________
Encoder-11-MultiHeadSelfAttenti (None, 150, 768)     0           Encoder-11-MultiHeadSelfAttention
__________________________________________________________________________________________________
Encoder-11-MultiHeadSelfAttenti (None, 150, 768)     0           Encoder-10-FeedForward-Norm[0][0]
                                                                 Encoder-11-MultiHeadSelfAttention
__________________________________________________________________________________________________
Encoder-11-MultiHeadSelfAttenti (None, 150, 768)     1536        Encoder-11-MultiHeadSelfAttention
__________________________________________________________________________________________________
Encoder-11-FeedForward (FeedFor (None, 150, 768)     4722432     Encoder-11-MultiHeadSelfAttention
__________________________________________________________________________________________________
Encoder-11-FeedForward-Dropout  (None, 150, 768)     0           Encoder-11-FeedForward[0][0]
__________________________________________________________________________________________________
Encoder-11-FeedForward-Add (Add (None, 150, 768)     0           Encoder-11-MultiHeadSelfAttention
                                                                 Encoder-11-FeedForward-Dropout[0]
__________________________________________________________________________________________________
Encoder-11-FeedForward-Norm (La (None, 150, 768)     1536        Encoder-11-FeedForward-Add[0][0]
__________________________________________________________________________________________________
Encoder-12-MultiHeadSelfAttenti (None, 150, 768)     2362368     Encoder-11-FeedForward-Norm[0][0]
__________________________________________________________________________________________________
Encoder-12-MultiHeadSelfAttenti (None, 150, 768)     0           Encoder-12-MultiHeadSelfAttention
__________________________________________________________________________________________________
Encoder-12-MultiHeadSelfAttenti (None, 150, 768)     0           Encoder-11-FeedForward-Norm[0][0]
                                                                 Encoder-12-MultiHeadSelfAttention
__________________________________________________________________________________________________
Encoder-12-MultiHeadSelfAttenti (None, 150, 768)     1536        Encoder-12-MultiHeadSelfAttention
__________________________________________________________________________________________________
Encoder-12-FeedForward (FeedFor (None, 150, 768)     4722432     Encoder-12-MultiHeadSelfAttention
__________________________________________________________________________________________________
Encoder-12-FeedForward-Dropout  (None, 150, 768)     0           Encoder-12-FeedForward[0][0]
__________________________________________________________________________________________________
Encoder-12-FeedForward-Add (Add (None, 150, 768)     0           Encoder-12-MultiHeadSelfAttention
                                                                 Encoder-12-FeedForward-Dropout[0]
__________________________________________________________________________________________________
Encoder-12-FeedForward-Norm (La (None, 150, 768)     1536        Encoder-12-FeedForward-Add[0][0]
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 150, 256)     918528      Encoder-12-FeedForward-Norm[0][0]
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, 150, 33)      8481        bidirectional_1[0][0]
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 150, 33)      0           time_distributed_1[0][0]
__________________________________________________________________________________________________WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Bert-base/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.


crf_1 (CRF)                     (None, 150, 33)      2277        dropout_1[0][0]
==================================================================================================
Total params: 102,328,326
Trainable params: 102,328,326
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/500
 - 72s - loss: 28.7404 - crf_accuracy: 0.0429

Epoch 00001: loss improved from inf to 28.74035, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 2/500
 - 43s - loss: 28.5282 - crf_accuracy: 0.1550

Epoch 00002: loss improved from 28.74035 to 28.52817, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 3/500
 - 41s - loss: 28.1905 - crf_accuracy: 0.3163

Epoch 00003: loss improved from 28.52817 to 28.19052, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 4/500
 - 41s - loss: 27.9276 - crf_accuracy: 0.3535

Epoch 00004: loss improved from 28.19052 to 27.92757, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 5/500
 - 41s - loss: 27.7257 - crf_accuracy: 0.3504

Epoch 00005: loss improved from 27.92757 to 27.72573, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 6/500
 - 40s - loss: 27.5877 - crf_accuracy: 0.3611

Epoch 00006: loss improved from 27.72573 to 27.58769, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 7/500
 - 41s - loss: 27.4533 - crf_accuracy: 0.3882

Epoch 00007: loss improved from 27.58769 to 27.45330, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 8/500
 - 41s - loss: 27.2630 - crf_accuracy: 0.4428

Epoch 00008: loss improved from 27.45330 to 27.26300, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 9/500
 - 41s - loss: 27.0555 - crf_accuracy: 0.4998

Epoch 00009: loss improved from 27.26300 to 27.05554, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 10/500
 - 41s - loss: 26.8326 - crf_accuracy: 0.5647

Epoch 00010: loss improved from 27.05554 to 26.83259, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 11/500
 - 41s - loss: 26.6640 - crf_accuracy: 0.6105

Epoch 00011: loss improved from 26.83259 to 26.66398, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 12/500
 - 41s - loss: 26.5107 - crf_accuracy: 0.6526

Epoch 00012: loss improved from 26.66398 to 26.51065, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 13/500
 - 41s - loss: 26.3605 - crf_accuracy: 0.7009

Epoch 00013: loss improved from 26.51065 to 26.36045, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 14/500
 - 41s - loss: 26.2546 - crf_accuracy: 0.7319

Epoch 00014: loss improved from 26.36045 to 26.25460, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 15/500
 - 41s - loss: 26.1543 - crf_accuracy: 0.7548

Epoch 00015: loss improved from 26.25460 to 26.15429, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 16/500
 - 41s - loss: 26.0596 - crf_accuracy: 0.7760

Epoch 00016: loss improved from 26.15429 to 26.05960, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 17/500
 - 42s - loss: 25.9790 - crf_accuracy: 0.7934

Epoch 00017: loss improved from 26.05960 to 25.97904, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 18/500
 - 64s - loss: 25.9052 - crf_accuracy: 0.8161

Epoch 00018: loss improved from 25.97904 to 25.90524, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 19/500
 - 61s - loss: 25.8397 - crf_accuracy: 0.8313

Epoch 00019: loss improved from 25.90524 to 25.83973, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 20/500
 - 43s - loss: 25.7631 - crf_accuracy: 0.8498

Epoch 00020: loss improved from 25.83973 to 25.76309, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 21/500
 - 42s - loss: 25.7025 - crf_accuracy: 0.8635

Epoch 00021: loss improved from 25.76309 to 25.70253, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 22/500
 - 59s - loss: 25.6547 - crf_accuracy: 0.8728

Epoch 00022: loss improved from 25.70253 to 25.65475, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 23/500
 - 63s - loss: 25.6218 - crf_accuracy: 0.8833

Epoch 00023: loss improved from 25.65475 to 25.62176, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 24/500
 - 61s - loss: 25.5759 - crf_accuracy: 0.8914

Epoch 00024: loss improved from 25.62176 to 25.57592, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 25/500
 - 61s - loss: 25.5380 - crf_accuracy: 0.9033

Epoch 00025: loss improved from 25.57592 to 25.53798, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 26/500
 - 60s - loss: 25.4990 - crf_accuracy: 0.9110

Epoch 00026: loss improved from 25.53798 to 25.49899, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 27/500
 - 59s - loss: 25.4754 - crf_accuracy: 0.9162

Epoch 00027: loss improved from 25.49899 to 25.47536, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 28/500
 - 61s - loss: 25.4359 - crf_accuracy: 0.9241

Epoch 00028: loss improved from 25.47536 to 25.43591, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 29/500
 - 60s - loss: 25.4131 - crf_accuracy: 0.9285

Epoch 00029: loss improved from 25.43591 to 25.41310, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 30/500
 - 59s - loss: 25.3908 - crf_accuracy: 0.9340

Epoch 00030: loss improved from 25.41310 to 25.39081, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 31/500
 - 59s - loss: 25.3695 - crf_accuracy: 0.9389

Epoch 00031: loss improved from 25.39081 to 25.36950, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 32/500
 - 60s - loss: 25.3555 - crf_accuracy: 0.9402

Epoch 00032: loss improved from 25.36950 to 25.35548, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 33/500
 - 59s - loss: 25.3327 - crf_accuracy: 0.9461

Epoch 00033: loss improved from 25.35548 to 25.33273, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 34/500
 - 59s - loss: 25.3212 - crf_accuracy: 0.9479

Epoch 00034: loss improved from 25.33273 to 25.32116, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 35/500
 - 60s - loss: 25.3121 - crf_accuracy: 0.9481

Epoch 00035: loss improved from 25.32116 to 25.31212, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 36/500
 - 53s - loss: 25.2922 - crf_accuracy: 0.9549

Epoch 00036: loss improved from 25.31212 to 25.29215, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 37/500
 - 54s - loss: 25.2841 - crf_accuracy: 0.9584

Epoch 00037: loss improved from 25.29215 to 25.28405, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 38/500
 - 60s - loss: 25.2744 - crf_accuracy: 0.9604

Epoch 00038: loss improved from 25.28405 to 25.27438, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 39/500
 - 60s - loss: 25.2638 - crf_accuracy: 0.9631

Epoch 00039: loss improved from 25.27438 to 25.26385, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 40/500
 - 60s - loss: 25.2545 - crf_accuracy: 0.9647

Epoch 00040: loss improved from 25.26385 to 25.25452, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 41/500
 - 59s - loss: 25.2461 - crf_accuracy: 0.9679

Epoch 00041: loss improved from 25.25452 to 25.24607, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 42/500
 - 57s - loss: 25.2347 - crf_accuracy: 0.9706

Epoch 00042: loss improved from 25.24607 to 25.23470, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 43/500
 - 58s - loss: 25.2237 - crf_accuracy: 0.9725

Epoch 00043: loss improved from 25.23470 to 25.22366, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 44/500
 - 59s - loss: 25.2246 - crf_accuracy: 0.9734

Epoch 00044: loss did not improve from 25.22366
Epoch 45/500
 - 58s - loss: 25.2178 - crf_accuracy: 0.9736

Epoch 00045: loss improved from 25.22366 to 25.21776, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 46/500
 - 60s - loss: 25.2142 - crf_accuracy: 0.9759

Epoch 00046: loss improved from 25.21776 to 25.21420, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 47/500
 - 58s - loss: 25.2049 - crf_accuracy: 0.9777

Epoch 00047: loss improved from 25.21420 to 25.20486, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 48/500
 - 58s - loss: 25.2052 - crf_accuracy: 0.9774

Epoch 00048: loss did not improve from 25.20486
Epoch 49/500
 - 58s - loss: 25.2116 - crf_accuracy: 0.9759

Epoch 00049: loss did not improve from 25.20486
Epoch 50/500
 - 58s - loss: 25.2182 - crf_accuracy: 0.9725

Epoch 00050: loss did not improve from 25.20486
Epoch 51/500
 - 59s - loss: 25.2104 - crf_accuracy: 0.9733

Epoch 00051: loss did not improve from 25.20486
Epoch 52/500
 - 53s - loss: 25.2003 - crf_accuracy: 0.9773

Epoch 00052: loss improved from 25.20486 to 25.20033, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 53/500
 - 53s - loss: 25.1948 - crf_accuracy: 0.9785

Epoch 00053: loss improved from 25.20033 to 25.19476, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 54/500
 - 58s - loss: 25.2080 - crf_accuracy: 0.9754

Epoch 00054: loss did not improve from 25.19476
Epoch 55/500
 - 58s - loss: 25.1940 - crf_accuracy: 0.9794

Epoch 00055: loss improved from 25.19476 to 25.19399, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 56/500
 - 57s - loss: 25.1865 - crf_accuracy: 0.9824

Epoch 00056: loss improved from 25.19399 to 25.18649, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 57/500
 - 60s - loss: 25.1825 - crf_accuracy: 0.9820

Epoch 00057: loss improved from 25.18649 to 25.18250, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 58/500
 - 58s - loss: 25.1889 - crf_accuracy: 0.9802

Epoch 00058: loss did not improve from 25.18250
Epoch 59/500
 - 60s - loss: 25.1757 - crf_accuracy: 0.9846

Epoch 00059: loss improved from 25.18250 to 25.17572, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 60/500
 - 59s - loss: 25.1693 - crf_accuracy: 0.9868

Epoch 00060: loss improved from 25.17572 to 25.16928, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 61/500
 - 59s - loss: 25.1765 - crf_accuracy: 0.9837

Epoch 00061: loss did not improve from 25.16928
Epoch 62/500
 - 59s - loss: 25.1685 - crf_accuracy: 0.9860

Epoch 00062: loss improved from 25.16928 to 25.16850, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 63/500
 - 58s - loss: 25.1647 - crf_accuracy: 0.9865

Epoch 00063: loss improved from 25.16850 to 25.16469, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 64/500
 - 57s - loss: 25.1658 - crf_accuracy: 0.9864

Epoch 00064: loss did not improve from 25.16469
Epoch 65/500
 - 57s - loss: 25.1572 - crf_accuracy: 0.9878

Epoch 00065: loss improved from 25.16469 to 25.15725, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 66/500
 - 59s - loss: 25.1603 - crf_accuracy: 0.9879

Epoch 00066: loss did not improve from 25.15725
Epoch 67/500
 - 59s - loss: 25.1551 - crf_accuracy: 0.9887

Epoch 00067: loss improved from 25.15725 to 25.15510, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 68/500
 - 57s - loss: 25.1550 - crf_accuracy: 0.9893

Epoch 00068: loss improved from 25.15510 to 25.15501, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 69/500
 - 52s - loss: 25.1518 - crf_accuracy: 0.9891

Epoch 00069: loss improved from 25.15501 to 25.15179, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 70/500
 - 60s - loss: 25.1494 - crf_accuracy: 0.9907

Epoch 00070: loss improved from 25.15179 to 25.14938, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 71/500
 - 59s - loss: 25.1496 - crf_accuracy: 0.9893

Epoch 00071: loss did not improve from 25.14938
Epoch 72/500
 - 59s - loss: 25.1484 - crf_accuracy: 0.9895

Epoch 00072: loss improved from 25.14938 to 25.14841, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 73/500
 - 60s - loss: 25.1562 - crf_accuracy: 0.9866

Epoch 00073: loss did not improve from 25.14841
Epoch 74/500
 - 58s - loss: 25.1536 - crf_accuracy: 0.9877

Epoch 00074: loss did not improve from 25.14841
Epoch 75/500
 - 58s - loss: 25.1502 - crf_accuracy: 0.9888

Epoch 00075: loss did not improve from 25.14841
Epoch 76/500
 - 58s - loss: 25.1543 - crf_accuracy: 0.9876

Epoch 00076: loss did not improve from 25.14841
Epoch 77/500
 - 60s - loss: 25.1580 - crf_accuracy: 0.9865

Epoch 00077: loss did not improve from 25.14841
Epoch 78/500
 - 59s - loss: 25.1531 - crf_accuracy: 0.9879

Epoch 00078: loss did not improve from 25.14841
Epoch 79/500
 - 58s - loss: 25.1533 - crf_accuracy: 0.9889

Epoch 00079: loss did not improve from 25.14841
Epoch 80/500
 - 60s - loss: 25.1483 - crf_accuracy: 0.9897

Epoch 00080: loss improved from 25.14841 to 25.14827, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 81/500
 - 59s - loss: 25.1463 - crf_accuracy: 0.9901

Epoch 00081: loss improved from 25.14827 to 25.14628, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 82/500
 - 60s - loss: 25.1467 - crf_accuracy: 0.9896

Epoch 00082: loss did not improve from 25.14628
Epoch 83/500
 - 59s - loss: 25.1471 - crf_accuracy: 0.9902

Epoch 00083: loss did not improve from 25.14628
Epoch 84/500
 - 60s - loss: 25.1408 - crf_accuracy: 0.9917

Epoch 00084: loss improved from 25.14628 to 25.14084, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 85/500
 - 47s - loss: 25.1405 - crf_accuracy: 0.9909

Epoch 00085: loss improved from 25.14084 to 25.14049, saving model to ./models/pulmonary_chinese_L-12_H-768_A-12_ner.h5
Epoch 86/500
 - 60s - loss: 25.1427 - crf_accuracy: 0.9908

Epoch 00086: loss did not improve from 25.14049
Epoch 87/500
 - 60s - loss: 25.1424 - crf_accuracy: 0.9905

Epoch 00087: loss did not improve from 25.14049
Epoch 88/500
 - 61s - loss: 25.1406 - crf_accuracy: 0.9914

Epoch 00088: loss did not improve from 25.14049
Epoch 89/500
 - 59s - loss: 25.1428 - crf_accuracy: 0.9907

Epoch 00089: loss did not improve from 25.14049
Epoch 90/500
 - 59s - loss: 25.1426 - crf_accuracy: 0.9905

Epoch 00090: loss did not improve from 25.14049
Epoch 91/500
 - 59s - loss: 25.1421 - crf_accuracy: 0.9912

Epoch 00091: loss did not improve from 25.14049
Epoch 92/500
 - 61s - loss: 25.1482 - crf_accuracy: 0.9898

Epoch 00092: loss did not improve from 25.14049
Epoch 93/500
 - 60s - loss: 25.1714 - crf_accuracy: 0.9851

Epoch 00093: loss did not improve from 25.14049
Epoch 94/500
 - 59s - loss: 25.1592 - crf_accuracy: 0.9867

Epoch 00094: loss did not improve from 25.14049
Epoch 95/500
 - 60s - loss: 25.1645 - crf_accuracy: 0.9875

Epoch 00095: loss did not improve from 25.14049
Epoch 00095: early stopping